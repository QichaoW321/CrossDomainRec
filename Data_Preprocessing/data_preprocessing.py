# -*- coding: utf-8 -*-
"""data_preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16Q3ICppS1ib71gP9zPb0uR6lAbBsoCnN
"""

import pandas as pd
import os



# Sample data load
books = pd.read_csv('books.csv', header=None)
movies_and_tv = pd.read_csv('movies_and_tv.csv', header=None)

# Setting column names
books.columns = ['asin', 'reviewerID', 'overall', 'unixReviewTime']
movies_and_tv.columns = ['asin', 'reviewerID', 'overall', 'unixReviewTime']



import pandas as pd

def load_and_preprocess(file_path, column_names):
    """
    Loads the CSV file, sets the column names, and preprocesses the data.
    """
    data = pd.read_csv(file_path, header=None)
    data.columns = column_names
    # Convert the necessary columns to appropriate data types
    data['overall'] = pd.to_numeric(data['overall'], errors='coerce')
    data['unixReviewTime'] = pd.to_numeric(data['unixReviewTime'], errors='coerce')
    # Drop rows with NaN values that resulted from conversion errors
    data.dropna(subset=['overall', 'unixReviewTime'], inplace=True)
    return data


def filter_asins(dataset):
    """
    Filters out ASINs with less than 10 appearances using groupby
    """
    asin_counts = dataset.groupby('asin').size()
    valid_asins = asin_counts[asin_counts >= 10].index
    return dataset[dataset['asin'].isin(valid_asins)]

def find_frequent_users(books, movies_and_tv):
    """
    Finds User IDs with at least 10 purchases in both datasets.
    """
    books_users = books.groupby('reviewerID').size()
    movies_users = movies_and_tv.groupby('reviewerID').size()

    frequent_books_users = books_users[books_users >= 10].index
    frequent_movies_users = movies_users[movies_users >= 10].index

    return set(frequent_books_users).intersection(frequent_movies_users)

# Column names for the datasets
column_names = ['asin', 'reviewerID', 'overall', 'unixReviewTime']

# Load and preprocess the data
books = load_and_preprocess('books.csv', column_names)
movies_and_tv = load_and_preprocess('movies_and_tv.csv', column_names)

filtered_books = filter_asins(books)
filtered_movies_and_tv = filter_asins(movies_and_tv)

# Sorting the datasets
sorted_books = filtered_books.sort_values(by='unixReviewTime')
sorted_movies_and_tv = filtered_movies_and_tv.sort_values(by='unixReviewTime')

# Finding frequent users
frequent_users = find_frequent_users(sorted_books, sorted_movies_and_tv)

# Save the frequent users to a file
with open('frequent_users.txt', 'w') as file:
    for user_id in frequent_users:
        file.write(f'{user_id}\n')

print("Frequent User IDs have been saved to frequent_users.txt")



filtered_books_for_users = books[books['reviewerID'].isin(frequent_users)]
filtered_movies_and_tv_for_users = movies_and_tv[movies_and_tv['reviewerID'].isin(frequent_users)]

filtered_movies_and_tv_for_users.head(10)

# Merge the metadata with the filtered datasets based on the 'asin' column
meta_movie = pd.read_csv('meta_Movies_and_TV_Complete.csv', header=0)
meta_book = pd.read_csv('meta_Books_Complete.csv', header=0)
books_with_meta = pd.merge(filtered_books_for_users, meta_book, on='asin', how='left')
movies_and_tv_with_meta = pd.merge(filtered_movies_and_tv_for_users, meta_movie, on='asin', how='left')

if not os.path.exists('10-10-filtered-data'):
    os.makedirs('10-10-filtered-data')

books_with_meta.to_csv('10-10-filtered-data/books_with_meta.csv', index=False)
movies_and_tv_with_meta.to_csv('10-10-filtered-data/movies_and_tv_with_meta.csv', index=False)

import matplotlib.pyplot as plt

df_movie = pd.read_csv("10-10-filtered-data/movies_and_tv_with_meta.csv")
len(df_movie)

plt.hist(df_movie['overall'], bins=50, edgecolor='black')  # Adjust bins as needed
plt.title('Histogram of Overall Ratings')
plt.xlabel('Ratings')
plt.ylabel('Frequency')
plt.show()

df_movie['like_or_dislike'] = np.where(df_movie['overall'] > 3, 'like', 'dislike')
df_movie['like_or_dislike_digit'] = np.where(df_movie['overall'] > 3, 1, 0)

# Save the modified DataFrame to a new CSV file for the movies dataset
df_movie.to_csv('10-10-filtered-data/movies_with_like_dislike.csv', index=False)



